{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVkFlWknLxI96nnY1Jucec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ouafighizlene21/classification_tid2013_cnn.ipynb/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Importer les biblioth√®ques n√©cessaires / Import Required Libraries  \n",
        "Importer les biblioth√®ques essentielles pour la classification d‚Äôimages avec un mod√®le CNN,  \n",
        "y compris le traitement des images, la construction du mod√®le, l'entra√Ænement, l'encodage des labels et l'affichage des r√©sultats.  \n",
        "Import essential libraries for image classification using a CNN model,  \n",
        "including image processing, model building, training, label encoding, and result visualization.\n"
      ],
      "metadata": {
        "id": "bzkv1Npo905B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HCBD4NlrcxNC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîó Monter Google Drive / Mount Google Drive  \n",
        "Connecter Google Colab √† Google Drive pour acc√©der aux fichiers stock√©s.  \n",
        "Connect Google Colab to Google Drive to access stored files.\n"
      ],
      "metadata": {
        "id": "u0xTJTcdAPME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8EXAu_cc2Ch",
        "outputId": "5fccaba7-4951-44ea-dc8b-1ea8cf2aa1f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üóÇÔ∏è D√©finir les chemins d‚Äôacc√®s aux images / Set Image Paths  \n",
        "D√©finir les chemins des images de r√©f√©rence et des images distordues stock√©es dans Google Drive.  \n",
        "Set the paths to reference and distorted images stored in Google Drive.\n"
      ],
      "metadata": {
        "id": "xsEJW5xXAVnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D√©finir le chemin vers les images de r√©frence\n",
        "reference_dir = '/content/drive/My Drive/TID2013/reference_images'\n",
        "# D√©finir le chemin vers les images de r√©frence\n",
        "distorted_dir = '/content/drive/My Drive/TID2013/distorted_images'"
      ],
      "metadata": {
        "id": "Hf55PYgtc4Dj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñºÔ∏è Charger et pr√©parer les images / Load and Prepare Images  \n",
        "Charger les images de r√©f√©rence et distordues depuis leurs r√©pertoires respectifs, les redimensionner √† 224x224 pixels,  \n",
        "les convertir en tableaux, les normaliser, puis attribuer une √©tiquette √† chaque image.  \n",
        "Load reference and distorted images from their respective directories, resize them to 224x224 pixels,  \n",
        "convert them to arrays, normalize them, and assign a label to each image.\n"
      ],
      "metadata": {
        "id": "xpOO7Od3Aeif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tid2013(data_dir, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img_file in os.listdir(data_dir):\n",
        "        img_path = os.path.join(data_dir, img_file)\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img / 255.0\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "ref_images, ref_labels = load_tid2013(reference_dir, 'reference')\n",
        "dist_images, dist_labels = load_tid2013(distorted_dir, 'distorted')\n",
        "\n",
        "# Combiner les donn√©es des deux r√©pertoires\n",
        "images = np.array(ref_images + dist_images)\n",
        "labels = np.array(ref_labels + dist_labels)"
      ],
      "metadata": {
        "id": "Xrqc3dYZc6ap"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÇÔ∏è Diviser les donn√©es en ensembles d‚Äôentra√Ænement et de test / Split Data into Training and Testing Sets  \n",
        "Diviser les images et leurs √©tiquettes en un ensemble d‚Äôentra√Ænement (80%) et un ensemble de test (20%) pour √©valuer les performances du mod√®le.  \n",
        "Split the images and their labels into a training set (80%) and a testing set (20%) to evaluate model performance.\n"
      ],
      "metadata": {
        "id": "kc3rO4R8BI8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zMGlO5hNdDlg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üî§ Encoder les √©tiquettes / Encode Labels  \n",
        "Utiliser `LabelEncoder` pour convertir les √©tiquettes textuelles (comme \"reference\" et \"distorted\") en valeurs num√©riques.  \n",
        "`fit_transform` est appliqu√© sur les donn√©es d'entra√Ænement pour ajuster et transformer, tandis que `transform` est utilis√© sur les donn√©es de test.  \n",
        "Use `LabelEncoder` to convert textual labels (e.g., \"reference\" and \"distorted\") into numeric values.  \n",
        "Apply `fit_transform` on the training set to fit and transform simultaneously, and use `transform` on the test set to apply the learned mapping.\n"
      ],
      "metadata": {
        "id": "OS393X3gBTIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#utilisez fit_transform sur les donn√©es d'entra√Ænement pour ajuster et transformer simultan√©ment, et utilisez transform sur les donn√©es de test ou toute nouvelle donn√©e pour appliquer la transformation apprise.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Initialiser l'encodeur\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Encoder les √©tiquettes d'entra√Ænement\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "\n",
        "# Encoder les √©tiquettes de test\n",
        "y_test_encoded = le.transform(y_test)\n",
        "\n",
        "# Afficher les classes apprises par l'encodeur\n",
        "print(\"Classes apprises par l'encodeur :\", le.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDshQFiTyoYM",
        "outputId": "5dc15b4b-559e-4c02-b2fd-0e3dbce78449"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes apprises par l'encodeur : ['distorted' 'reference']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Construire et compiler le mod√®le CNN / Build and Compile the CNN Model  \n",
        "Encoder les √©tiquettes en vecteurs one-hot pour la classification multiclasse.  \n",
        "Construire un mod√®le CNN avec des couches de convolution, de max-pooling, une couche flatten,  \n",
        "et des couches denses enti√®rement connect√©es. Compiler ensuite le mod√®le avec l'optimiseur Adam  \n",
        "et la fonction de perte `categorical_crossentropy`.  \n",
        "Encode the labels using one-hot encoding for multi-class classification.  \n",
        "Build a CNN model with convolutional layers, max-pooling, a flatten layer,  \n",
        "and fully connected dense layers. Then compile the model using the Adam optimizer  \n",
        "and the `categorical_crossentropy` loss function.\n"
      ],
      "metadata": {
        "id": "PWOrJTC9Bms2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodage one-hot des labels\n",
        "y_train_one_hot = to_categorical(y_train_encoded, num_classes=2)\n",
        "y_test_one_hot = to_categorical(y_test_encoded, num_classes=2)\n",
        "\n",
        "# Cr√©ation du mod√®le\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution + MaxPooling\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Aplatir les sorties de la derni√®re couche de convolution\n",
        "model.add(Flatten())\n",
        "\n",
        "# Couches enti√®rement connect√©es\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))  # 2 neurones avec softmax pour multi-classes\n",
        "\n",
        "# Compilation du mod√®le\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Afficher le r√©sum√© du mod√®le\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "GgOR8EmGoKOr",
        "outputId": "97741be5-14e4-42cd-a9ca-70248840d8a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ           \u001b[38;5;34m896\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   ‚îÇ        \u001b[38;5;34m18,496\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ        \u001b[38;5;34m73,856\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ flatten (\u001b[38;5;33mFlatten\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ    \u001b[38;5;34m11,075,712\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              ‚îÇ           \u001b[38;5;34m258\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,169,218\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,218</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,218\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,218</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Entra√Æner le mod√®le CNN / Train the CNN Model  \n",
        "Entra√Æner le mod√®le sur l‚Äôensemble d'entra√Ænement pendant 10 √©poques avec une taille de lot de 32.  \n",
        "Les performances sont valid√©es √† chaque √©poque sur l‚Äôensemble de test.  \n",
        "Train the model on the training set for 10 epochs with a batch size of 32.  \n",
        "Performance is validated at each epoch on the test set.\n"
      ],
      "metadata": {
        "id": "bEe7NzGaHwuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entra√Ænement du mod√®le\n",
        "history = model.fit(X_train, y_train_one_hot, epochs=10, batch_size=32, validation_data=(X_test, y_test_one_hot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1cjUMvF48hl",
        "outputId": "4b8644b0-77f2-4cc9-f18c-8efd55399522"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 4s/step - accuracy: 0.9877 - loss: 0.0991 - val_accuracy: 0.9934 - val_loss: 0.0448\n",
            "Epoch 2/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 4s/step - accuracy: 0.9918 - loss: 0.0545 - val_accuracy: 0.9934 - val_loss: 0.0413\n",
            "Epoch 3/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 4s/step - accuracy: 0.9892 - loss: 0.0676 - val_accuracy: 0.9934 - val_loss: 0.0483\n",
            "Epoch 4/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 3s/step - accuracy: 0.9911 - loss: 0.0613 - val_accuracy: 0.9934 - val_loss: 0.0451\n",
            "Epoch 5/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 3s/step - accuracy: 0.9931 - loss: 0.0475 - val_accuracy: 0.9934 - val_loss: 0.0528\n",
            "Epoch 6/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 3s/step - accuracy: 0.9906 - loss: 0.0591 - val_accuracy: 0.9934 - val_loss: 0.0433\n",
            "Epoch 7/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 3s/step - accuracy: 0.9915 - loss: 0.0514 - val_accuracy: 0.9934 - val_loss: 0.0419\n",
            "Epoch 8/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 3s/step - accuracy: 0.9930 - loss: 0.0427 - val_accuracy: 0.9934 - val_loss: 0.0456\n",
            "Epoch 9/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 3s/step - accuracy: 0.9922 - loss: 0.0461 - val_accuracy: 0.9934 - val_loss: 0.0511\n",
            "Epoch 10/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 3s/step - accuracy: 0.9933 - loss: 0.0429 - val_accuracy: 0.9934 - val_loss: 0.0520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Sauvegarder le mod√®le et l‚Äôhistorique d'entra√Ænement / Save the Model and Training History  \n",
        "Sauvegarder le mod√®le entra√Æn√© au format `.keras` pour pouvoir le recharger ult√©rieurement sans le r√©entra√Æner.  \n",
        "Enregistrer √©galement l'historique d'entra√Ænement (pr√©cision, perte, etc.) dans un fichier `.pkl`  \n",
        "pour pouvoir visualiser les courbes plus tard.  \n",
        "Save the trained model in `.keras` format to reload it later without retraining.  \n",
        "Also save the training history (accuracy, loss, etc.) in a `.pkl` file to visualize the curves later.\n"
      ],
      "metadata": {
        "id": "sQ04pfUpTCt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Sauvegarder l'historique d'entra√Ænement\n",
        "with open('historique_entra√Ænement.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "# Sauvegarde du mod√®le dans le nouveau format .keras\n",
        "model.save('mon_modele_entraine.keras')\n"
      ],
      "metadata": {
        "id": "whrvhtJATQQn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Recharger l‚Äôhistorique d‚Äôentra√Ænement / Reload Training History  \n",
        "Charger les m√©triques d‚Äôentra√Ænement pr√©c√©demment sauvegard√©es (pr√©cision, perte, etc.)  \n",
        "depuis un fichier `.pkl` pour permettre leur visualisation sans relancer l'entra√Ænement.  \n",
        "Load previously saved training metrics (accuracy, loss, etc.)  \n",
        "from a `.pkl` file to allow visualization without retraining.\n"
      ],
      "metadata": {
        "id": "EwT8nbjZVaMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recharger l'historique\n",
        "with open('historique_entra√Ænement.pkl', 'rb') as f:\n",
        "    history_dict = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "AVyDwvCvUNHc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÇ Charger le mod√®le sauvegard√© / Load the Saved Model  \n",
        "Recharger le mod√®le CNN sauvegard√© au format `.keras` afin de l‚Äôutiliser pour l‚Äô√©valuation ou les pr√©dictions,  \n",
        "sans avoir √† le r√©entra√Æner.  \n",
        "Reload the CNN model saved in `.keras` format to use it for evaluation or predictions,  \n",
        "without retraining it.\n"
      ],
      "metadata": {
        "id": "CDY9Yne-VfI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le mod√®le sauvegard√©\n",
        "model = load_model('mon_modele_entraine.keras')\n"
      ],
      "metadata": {
        "id": "6HPsDUH0FON3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñºÔ∏è Pr√©parer une image pour la pr√©diction / Prepare an Image for Prediction  \n",
        "D√©finir une fonction pour charger une image, la redimensionner, la convertir en tableau numpy,  \n",
        "la normaliser et lui ajouter une dimension pour l‚Äôadapter √† l‚Äôentr√©e du mod√®le.  \n",
        "Define a function to load an image, resize it, convert it to a NumPy array,  \n",
        "normalize it, and add a batch dimension to fit the model input.\n"
      ],
      "metadata": {
        "id": "wkGlhEG6VkVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour pr√©parer l'image\n",
        "def prepare_image(img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)  # Charger l'image\n",
        "    img_array = image.img_to_array(img)  # Convertir en tableau numpy\n",
        "    img_array = img_array / 255.0  # Normaliser\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension pour le batch\n",
        "    return img_array\n"
      ],
      "metadata": {
        "id": "DuAbEC6LJOSJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üè∑Ô∏è Afficher les classes apprises par l‚Äôencodeur / Show Classes Learned by the Encoder  \n",
        "Afficher l‚Äôordre des classes (√©tiquettes) que le `LabelEncoder` a appris lors de l‚Äôencodage des donn√©es.  \n",
        "Cela permet de conna√Ætre la correspondance exacte entre les indices num√©riques (0, 1, ...) et les √©tiquettes textuelles (`reference`, `distorted`, etc.).  \n",
        "Display the order of class labels learned by the `LabelEncoder` when encoding data.  \n",
        "This ensures correct mapping between numeric indices (0, 1, ...) and textual labels (`reference`, `distorted`, etc.).\n"
      ],
      "metadata": {
        "id": "rIQ-ZReej6DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classes connues par l'encodeur :\", le.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY4wq8cMY2bT",
        "outputId": "eaa64ddf-4a5b-4258-a5fa-4dace0671e97"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes connues par l'encodeur : ['distorted' 'reference']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîé Pr√©dire la classe d‚Äôune image avec le mod√®le entra√Æn√© / Predict the Class of an Image Using the Trained Model  \n",
        "Charger une image issue du dossier des images distordues, la pr√©parer, et l‚Äôutiliser comme entr√©e pour le mod√®le CNN.  \n",
        "La pr√©diction est ensuite interpr√©t√©e en utilisant les classes apprises automatiquement par le `LabelEncoder`,  \n",
        "ce qui garantit la coh√©rence entre l‚Äôindex pr√©dit et le nom de la classe (`distorted`, `reference`, etc.).  \n",
        "Load a distorted image, preprocess it, and use it as input to the trained CNN model.  \n",
        "The predicted class index is mapped back to the actual class name using the labels learned by the `LabelEncoder`,  \n",
        "ensuring consistency between prediction index and true label (`distorted`, `reference`, etc.).\n"
      ],
      "metadata": {
        "id": "FNP_LYlPj-eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pr√©parer l'image pour la pr√©diction\n",
        "img_path = '/content/drive/My Drive/TID2013/distorted_images/i01_18_4.jpg'\n",
        "prepared_image = prepare_image(img_path)\n",
        "\n",
        "# Faire la pr√©diction\n",
        "predictions = model.predict(prepared_image)\n",
        "\n",
        "# Utiliser directement les classes de l'encodeur\n",
        "predicted_label = le.classes_[np.argmax(predictions)]\n",
        "\n",
        "print(f\"Classe pr√©dite : {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5BXvPlWYxNO",
        "outputId": "ad0717c9-79b5-4e9c-a88c-19965bacde87"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "Classe pr√©dite : distorted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Pr√©dire la classe d‚Äôune image avec le mod√®le entra√Æn√© / Predict the Class of an Image Using the Trained Model  \n",
        "Charger une image issue du dossier des images distordues, la pr√©parer, et l‚Äôutiliser comme entr√©e pour le mod√®le CNN.  \n",
        "La pr√©diction est ensuite interpr√©t√©e en utilisant les classes apprises automatiquement par le `LabelEncoder`,  \n",
        "ce qui garantit la coh√©rence entre l‚Äôindex pr√©dit et le nom de la classe (`distorted`, `reference`, etc.).  \n",
        "Load a distorted image, preprocess it, and use it as input to the trained CNN model.  \n",
        "The predicted class index is mapped back to the actual class name using the labels learned by the `LabelEncoder`,  \n",
        "ensuring consistency between prediction index and true label (`distorted`, `reference`, etc.).\n",
        "\n",
        "‚ö†Ô∏è **Remarque importante / Important Note:**  \n",
        "L‚Äôimage utilis√©e pour ce test provient du **dossier `reference_images`**,  \n",
        "mais le mod√®le a pr√©dit √† tort qu‚Äôelle appartient √† la classe `\"distorted\"`.  \n",
        "Cela montre que le mod√®le peut faire des erreurs, probablement √† cause du fort d√©s√©quilibre entre les classes lors de l'entra√Ænement.  \n",
        "The image used for this test comes from the **`reference_images` folder**,  \n",
        "but the model mistakenly predicted it as belonging to the `\"distorted\"` class.  \n",
        "This highlights that the model can make mistakes, likely due to strong class imbalance during training.\n"
      ],
      "metadata": {
        "id": "e4tQqXDosSqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pr√©parer l'image pour la pr√©diction\n",
        "img_path = '/content/drive/My Drive/TID2013/reference_images/I11.jpg'  # Chemin de l'image\n",
        "prepared_image = prepare_image(img_path)\n",
        "\n",
        "# Faire la pr√©diction\n",
        "predictions = model.predict(prepared_image)\n",
        "\n",
        "# Utiliser le m√™me ordre de classes que l'encodeur\n",
        "class_labels = list(le.classes_)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "predicted_label = class_labels[predicted_class[0]]\n",
        "\n",
        "print(f\"Classe pr√©dite : {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyfPBOVBYy5y",
        "outputId": "0bce7fcc-35d0-4cc1-dc99-8cd172086ba9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Classe pr√©dite : distorted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ö†Ô∏è Attention : correspondance des classes et pr√©dictions  \n",
        "## ‚ö†Ô∏è Warning: Class Mapping and Predictions\n",
        "\n",
        "Lorsque vous utilisez `np.argmax(predictions)` pour obtenir l‚Äôindice de la classe pr√©dite,  \n",
        "il est **essentiel d‚Äôutiliser les vraies √©tiquettes apprises par le `LabelEncoder`**,  \n",
        "et **pas une liste manuelle comme `['reference', 'distorted']`**.\n",
        "\n",
        "When using `np.argmax(predictions)` to get the predicted class index,  \n",
        "it is **crucial to use the actual class labels learned by the `LabelEncoder`**,  \n",
        "and **not a manually defined list like `['reference', 'distorted']`**.\n",
        "\n",
        "---\n",
        "\n",
        "### üí° Mauvais exemple / Bad example:\n",
        "```python\n",
        "class_labels = ['reference', 'distorted']\n",
        "predicted_label = class_labels[np.argmax(predictions)]\n"
      ],
      "metadata": {
        "id": "eSZgzdiBrb1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pr√©parer l'image pour la pr√©diction\n",
        "img_path = '/content/drive/My Drive/TID2013/reference_images/I11.jpg'  # Chemin de l'image\n",
        "prepared_image = prepare_image(img_path)\n",
        "\n",
        "# Faire la pr√©diction\n",
        "predictions = model.predict(prepared_image)\n",
        "\n",
        "# Utiliser le m√™me ordre de classes que l'encodeur\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "class_labels = ['reference', 'distorted']  # Les √©tiquettes de tes classes\n",
        "predicted_label = class_labels[predicted_class[0]]\n",
        "\n",
        "print(f\"Classe pr√©dite : {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXs-60YUhs9W",
        "outputId": "fe17d3ea-0fc2-42d0-ff60-af21e0ce1cbf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Classe pr√©dite : reference\n"
          ]
        }
      ]
    }
  ]
}